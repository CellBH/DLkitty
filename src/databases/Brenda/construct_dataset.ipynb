{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdir = '../../../data/databases/Brenda/'\n",
    "fname = 'brenda.json'\n",
    "df = pd.read_json(fdir+fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove columns (EC numbers) that do not contain any $k_{cat}$ values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_cols = []\n",
    "for ECNumber in df.columns:\n",
    "    kcats = df[ECNumber].turnover_number\n",
    "    if (type(kcats) == float) and np.isnan(kcats):\n",
    "        remove_cols.append(ECNumber)\n",
    "len(remove_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(remove_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['1.1.1.1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to compare values in two organism/reference dictionaries\n",
    "def isequal_org_ref_map(map1, map2):\n",
    "    pH1 = map1['pH']\n",
    "    pH2 = map2['pH']\n",
    "    if np.isnan(pH1) and not(np.isnan(pH2)):\n",
    "        return False\n",
    "    elif not(np.isnan(pH1)) and np.isnan(pH1):\n",
    "        return False\n",
    "    elif not(np.isnan(pH1)) and not(np.isnan(pH2)) and pH1 != pH2:\n",
    "        return False\n",
    "\n",
    "    T1 = map1['Temperature']\n",
    "    T2 = map2['Temperature']\n",
    "    if np.isnan(T1) and not(np.isnan(T2)):\n",
    "        return False\n",
    "    elif not(np.isnan(T1)) and np.isnan(T2):\n",
    "        return False\n",
    "    elif not(np.isnan(T1)) and not(np.isnan(T2)) and T1 != T2:\n",
    "        return False\n",
    " \n",
    "    enz1 = map1['EnzymeType']\n",
    "    enz2 = map2['EnzymeType']\n",
    "    if len(enz1) == len(enz2):\n",
    "         if len(enz1) > 0 and not(np.array_equal(enz1, enz2)):\n",
    "              return False\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relevant information about pH, Temperature, EnzymeType and cosubstrates from each segment of kcat['comment']\n",
    "def parse_entry(entry, org_ref_map, org_inds, ref_inds, cosubstrate_list):\n",
    "    if 'pH' in entry:\n",
    "        pH = re.search('pH ?[0-9]+[.]*[0-9]*', entry)\n",
    "        if (pH):\n",
    "            pH = re.search('[0-9]+[.]*[0-9]*', pH.group()).group()\n",
    "            pH = pH.replace('..', '.')\n",
    "            pH = float(pH)\n",
    "        else:\n",
    "            pH = re.search('at [0-9]+[.]*[0-9]* pH', entry)\n",
    "            if (pH):\n",
    "                pH = re.search('[0-9]+[.]*[0-9]*', pH.group()).group()\n",
    "                #print(entry)\n",
    "                pH = pH.replace('..', '.')\n",
    "                pH = float(pH)\n",
    "        if (pH):\n",
    "            for org in org_inds:\n",
    "                for ref in ref_inds:\n",
    "                    org_ref_map[(org, ref)]['pH'].append(pH)\n",
    "\n",
    "    if '°C' in entry:\n",
    "        temp = re.search('[0-9]+[.]*[0-9]* ?Â?°C', entry)\n",
    "        if (temp):\n",
    "            temp = re.search('[0-9]+[.]*[0-9]*', temp.group()).group()\n",
    "            temp = float(temp)\n",
    "        if (temp):\n",
    "            for org in org_inds:\n",
    "                for ref in ref_inds:\n",
    "                    org_ref_map[(org, ref)]['Temperature'].append(temp)\n",
    "                            \n",
    "    if ('zyme' in entry) or ('mutant' in entry) or ('mutated') in entry:\n",
    "        for org in org_inds:\n",
    "            for ref in ref_inds:\n",
    "                org_ref_map[(org, ref)]['EnzymeType'].append(entry)\n",
    "\n",
    "    if ('co-substrate' in entry) or ('cosubstrate' in entry):\n",
    "        cosubstrate = ''\n",
    "        entry = entry.replace('co-substrate', 'cosubstrate')\n",
    "        entry = entry.replace('cosubstrate:', 'cosubstrate')\n",
    "        entry = entry.replace('donor ', '')\n",
    "        if re.search('mM .+ as cosubstrate', entry):\n",
    "            cosubstrate = re.search('mM .+ as', entry).group()[3:-3]\n",
    "        elif re.search('with .+ as cosubstrate', entry):\n",
    "            cosubstrate = re.search('with .+ as', entry).group()[5:-3]\n",
    "        elif re.search('using .+ as cosubstrate', entry):\n",
    "            cosubstrate = re.search('using .* as', entry).group()[6:-3]\n",
    "        elif re.search('cosubstrate .+', entry):\n",
    "            cosubstrate = re.search('cosubstrate .+', entry).group()[12:]\n",
    "        \n",
    "        if cosubstrate != '' and cosubstrate[-1] == ' ':\n",
    "            cosubstrate = cosubstrate[:-1]\n",
    "        if ' or ' in cosubstrate:\n",
    "            cosubstrate = cosubstrate.split(' or ')[0]\n",
    "        if ' + ' in cosubstrate:\n",
    "            cosubstrate = cosubstrate.replace(' + ', ' and ')\n",
    "        \n",
    "        if cosubstrate != '':\n",
    "            for cosubstrate in cosubstrate.split(' and '):\n",
    "                cosubstrate_list.append(cosubstrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_comment(comment, org_ref_map, cosubstrate_list):\n",
    "    # each subcomment has #...# ... <...> pattern\n",
    "    # each subcomment can refer to multiple organisms and references \n",
    "    org_inds = re.search('#.*#', comment).group()[1:-1].split(',')\n",
    "    ref_inds = re.search('<.*>', comment).group()[1:-1].split(',')\n",
    "    # create a subdictionary for each (org, ref) pair\n",
    "    for org in org_inds:\n",
    "        for ref in ref_inds:\n",
    "            if not((org, ref) in org_ref_map):\n",
    "                org_ref_map[(org, ref)] = {'pH': [], 'Temperature': [], 'EnzymeType': [], 'UniProtID': np.nan, 'PubMedID': np.nan}\n",
    "    # resolve inconsistent use of commas to separate entries\n",
    "    entries = re.search('#[^#]*<', comment).group()[1:-1]\n",
    "    entries = entries.replace(' , ', ', ')\n",
    "    entries = entries.replace(',,', ',')\n",
    "    entries = entries.split(', ')\n",
    "    \n",
    "    for entry in entries:\n",
    "        parse_entry(entry, org_ref_map, org_inds, ref_inds, cosubstrate_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove data entries that cannot be uniquely mapped to temperature, pH or reference data\n",
    "def clean_org_ref_map(org_ref_map):\n",
    "    for i in org_ref_map.keys():\n",
    "        # If there are multiple associated temperature or pH values we ignore them\n",
    "        org_ref_map[i]['Temperature'] = np.unique(org_ref_map[i]['Temperature']) \n",
    "        if len(org_ref_map[i]['Temperature']) == 1:\n",
    "            org_ref_map[i]['Temperature'] = org_ref_map[i]['Temperature'][0]\n",
    "        else:\n",
    "            org_ref_map[i]['Temperature'] = np.nan\n",
    "        \n",
    "        org_ref_map[i]['pH'] = np.unique(org_ref_map[i]['pH']) \n",
    "        if len(org_ref_map[i]['pH']) == 1:\n",
    "            org_ref_map[i]['pH'] = org_ref_map[i]['pH'][0]\n",
    "        else:\n",
    "            org_ref_map[i]['pH'] = np.nan\n",
    "        \n",
    "        org_ref_map[i]['EnzymeType'] = np.unique(org_ref_map[i]['EnzymeType'])\n",
    "\n",
    "    # Remove reference data for clarity if an entry is associated with multiple references and otherwise identical data\n",
    "    keys = org_ref_map.copy().keys()\n",
    "    for key in keys:\n",
    "        if key in org_ref_map:\n",
    "            remove = False\n",
    "            for key2 in keys:\n",
    "                if (key2 in org_ref_map) and (key[0] == key2[0]) and (key[1] != key2[1]) and isequal_org_ref_map(org_ref_map[key], org_ref_map[key2]):\n",
    "                    remove = True\n",
    "                    if key2 in org_ref_map:\n",
    "                        del org_ref_map[key2]\n",
    "                    if not((key[0], '-') in org_ref_map):\n",
    "                        org_ref_map[(key[0], '-')] = org_ref_map[key]\n",
    "            if remove:\n",
    "                del org_ref_map[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_list = []\n",
    "\n",
    "for ECNumber in df.columns:\n",
    "    data = df[ECNumber]\n",
    "\n",
    "    # Create a map linking proteins to their UniProtIDs that are recorded in the database\n",
    "    uniprot_map = {}\n",
    "    if type(data.proteins) == dict:\n",
    "        for protein in data.proteins:\n",
    "            # accessions is always in the first element of the protein_info list\n",
    "            protein_info = data.proteins[protein][0]\n",
    "            if 'accessions' in protein_info: # always associated with 'source' = 'uniprot'\n",
    "                uniprot_map[protein] = protein_info['accessions'] # this can be a list longer than 1\n",
    "\n",
    "    # Extract kcat information\n",
    "    kcats = data.turnover_number\n",
    "    for kcat in kcats:\n",
    "        \n",
    "        # ---------------------------------------------------------------------------------- \n",
    "        # Parse the comments to extract any relevant data\n",
    "        \n",
    "        org_ref_map = {}\n",
    "        cosubstrate_list = []\n",
    "\n",
    "        if ('comment' in kcat):\n",
    "            # subcomments are separated by a semicolon\n",
    "            comments = kcat['comment'].split('; ')\n",
    "            for comment in comments:\n",
    "                parse_comment(comment, org_ref_map, cosubstrate_list)\n",
    "\n",
    "        clean_org_ref_map(org_ref_map)\n",
    "        cosubstrate_list = np.unique(cosubstrate_list)\n",
    "        \n",
    "        # ----------------------------------------------------------------------------------\n",
    "        # Parse the organism/reference combinations and leave only the unique entries\n",
    "        # Remove reference info if they cannot be uniquely identified\n",
    "\n",
    "        n_orgs = len(kcat['organisms'])\n",
    "        n_refs = len(kcat['references'])\n",
    "\n",
    "        if (n_orgs == 1) and (n_refs == 1):\n",
    "            org = kcat['organisms'][0] \n",
    "            ref = kcat['references'][0]\n",
    "            if bool(org_ref_map) and not((org, ref) in org_ref_map):\n",
    "                print(\"Unexpected organism/reference assignment\")\n",
    "            elif not(org_ref_map):\n",
    "                org_ref_map[(org, ref)] = {'pH': np.nan, 'Temperature': np.nan, 'EnzymeType': [], 'UniProtID': np.nan, 'PubMedID': np.nan}\n",
    "        elif (n_orgs == 1) and (n_refs > 1):\n",
    "            org = kcat['organisms'][0] \n",
    "            if not(org_ref_map):\n",
    "                org_ref_map[(org, '-')] = {'pH': np.nan, 'Temperature': np.nan, 'EnzymeType': [], 'UniProtID': np.nan, 'PubMedID': np.nan}\n",
    "        elif (n_orgs > 1) and (n_refs == 1):\n",
    "            ref = kcat['references'][0]\n",
    "            for org in kcat['organisms']:\n",
    "                if not((org, ref) in org_ref_map):\n",
    "                    org_ref_map[(org, ref)] = {'pH': np.nan, 'Temperature': np.nan, 'EnzymeType': [], 'UniProtID': np.nan, 'PubMedID': np.nan}\n",
    "        elif (n_orgs > 1) and (n_refs > 1):\n",
    "            org_keys = [key[0] for key in org_ref_map.keys()]\n",
    "            for org in kcat['organisms']:\n",
    "                # add an entry if the organism is not already associated with some reference \n",
    "                if not(org in org_keys):\n",
    "                    org_ref_map[(org, '-')] = {'pH': np.nan, 'Temperature': np.nan, 'EnzymeType': [], 'UniProtID': np.nan, 'PubMedID': np.nan}\n",
    "        else:\n",
    "            print(\"Unexpected number of organisms and references\") \n",
    "\n",
    "        # ----------------------------------------------------------------------------------\n",
    "        # Parse the protein/organism list and retrieve the associated UniProtIDs\n",
    "        # Note that protein and organism indices seem to be equivalent\n",
    "\n",
    "        for org in kcat['organisms']:\n",
    "            if org in uniprot_map:\n",
    "                for key in org_ref_map.keys():\n",
    "                    if key[0] == org:\n",
    "                        org_ref_map[key]['UniProtID'] = uniprot_map[org]\n",
    "\n",
    "        # ----------------------------------------------------------------------------------\n",
    "        # Parse the reference list and retrieve the associated PubmedIDs\n",
    "    \n",
    "        for key in org_ref_map:\n",
    "            if (key[1] != '-') and ('pmid' in data.references[key[1]]):\n",
    "                org_ref_map[key]['PubMedID'] = data.references[key[1]]['pmid']\n",
    "        \n",
    "        # ----------------------------------------------------------------------------------\n",
    "        # Retrieve the associated organisms\n",
    "\n",
    "        for key in org_ref_map:\n",
    "            org_ref_map[key]['Organism'] = data.organisms[key[0]]['value']\n",
    "\n",
    "        # ----------------------------------------------------------------------------------\n",
    "        # Extract data associated with each organism/reference combination\n",
    " \n",
    "        data_map = {\"ECNumber\": ECNumber, \"EnzymeName\": data['name']}\n",
    "\n",
    "        # kcat        \n",
    "        if 'num_value' in kcat:\n",
    "            data_map['parameter.startValue'] = kcat['num_value']\n",
    "            data_map['parameter.endValue'] = np.nan\n",
    "        elif 'min_value' in kcat:\n",
    "            data_map['parameter.startValue'] = kcat['min_value']\n",
    "            data_map['parameter.endValue'] = kcat['max_value']\n",
    "        else:\n",
    "            print(\"Inconsistent kcat value\")\n",
    "\n",
    "        data_map['parameter.standardDeviation'] = np.nan\n",
    "        data_map['parameter.unit'] = 's^(-1)'\n",
    "\n",
    "        # Substrate\n",
    "        data_map['Substrate'] = kcat['value']        \n",
    "        \n",
    "        # ----------------------------------------------------------------------------------\n",
    "        # Parse the reaction and cosubstrate lists to identify other co-substrates\n",
    "         \n",
    "        # Check if the reference and organism lists associated with kcat together with the kcat substrate have a unique hit in the reaction list\n",
    "        reaction_list = []\n",
    "        for reaction in data.reaction:\n",
    "            \n",
    "            if not('organisms' in reaction) or not('references' in reaction) or not('educts' in reaction):\n",
    "                #print(reaction)\n",
    "                continue\n",
    "            \n",
    "            org_check = np.all([org in reaction['organisms'] for org in kcat['organisms']])\n",
    "            ref_check = np.all([ref in reaction['references'] for ref in kcat['references']])\n",
    "            substrate_check = kcat['value'] in reaction['educts']\n",
    "            if org_check and ref_check and substrate_check:\n",
    "                educts = list(np.sort(reaction['educts']))\n",
    "                if not(educts in reaction_list):\n",
    "                    reaction_list.append(educts)\n",
    "        \n",
    "        if len(reaction_list) == 0:\n",
    "            data_map['Substrate'] = [kcat['value']]\n",
    "        elif len(reaction_list) == 1:\n",
    "            data_map['Substrate'] = reaction_list[0]\n",
    "        elif (len(reaction_list) > 1) and (len(cosubstrate_list) > 0):\n",
    "            # If the reaction cannot be uniquely assigned, try using the cosubstrates parsed from the comment to narrow it down\n",
    "            # NOTE: in a handful of cases, individual org/ref combinations may have different cosubstrates associated with it (would require a bit of a rewrite, ignoring it currently)\n",
    "            cosub_reaction_list = []\n",
    "            for reaction in reaction_list:\n",
    "                cosubstrate_check = np.all([cosubstrate in reaction for cosubstrate in cosubstrate_list])\n",
    "                if cosubstrate_check:\n",
    "                    cosub_reaction_list.append(reaction)\n",
    "            if len(cosub_reaction_list) == 1:\n",
    "                data_map['Substrate'] = cosub_reaction_list[0]\n",
    "            else:\n",
    "                # if cannot uniquely assign\n",
    "                data_map['Substrate'] = reaction_list[0]\n",
    "        else:\n",
    "            data_map['Substrate'] = [kcat['value']]\n",
    "\n",
    "        data_map['Substrate'] = np.sort(data_map['Substrate'])\n",
    "\n",
    "        # ----------------------------------------------------------------------------------\n",
    "        # Append data entries\n",
    "        \n",
    "        for key in org_ref_map.keys():\n",
    "            org_ref_map[key].update(data_map)\n",
    "            rows_list.append(org_ref_map[key])\n",
    "\n",
    "df = pd.DataFrame(rows_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(['Ethanol', 'NAD+'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse PubMedIDs as integers\n",
    "df['PubMedID'] = df['PubMedID'].astype('Int64')\n",
    "# remove duplicate entries\n",
    "df = df.loc[df.astype(str).drop_duplicates().index]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `parameter.endValue`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the number of $k_{cat}$ values with an associated `endValue`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(~df['parameter.endValue'].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[~df['parameter.endValue'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relatively few entries exist, so ignoring `endValue` seems to be the way to go. Discard any entries that have both `startValue` and `endValue` defined, and remove the `parameter.endValue` column completely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df['parameter.endValue'].isnull()\n",
    "df = df.drop('parameter.endValue', axis=1)\n",
    "df = df.loc[mask]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `pH`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(~df['pH'].isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Temperature`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(~df['Temperature'].isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'parameter.startValue': 'Value'})\n",
    "df = df.rename(columns={'parameter.standardDeviation': 'StandardDeviation'})\n",
    "df = df.drop('parameter.unit', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['PubMedID', 'Organism', 'Substrate', 'ECNumber', 'EnzymeName', 'EnzymeType', 'UniProtID', 'pH', 'Temperature', 'Value', 'StandardDeviation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df.astype(str).drop_duplicates().index\n",
    "df = df.loc[mask]\n",
    "df = df.reset_index(drop=True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdir = '../../../data/databases/Brenda/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(fdir+'kcats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(fdir+'kcats.json', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
