{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix downloaded dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redownload missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdir = '../../../data/databases/Sabio-RK/'\n",
    "fname = 'dataset_download.tsv'\n",
    "f = open(fdir+fname, 'r')\n",
    "lines = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certain database entries can be downloaded incompletely with the last line mostly missing (without `\\n`) for some ungodly reason. Manually fixing these missing entries in the corresponding text files by redownloading the corresponding entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in lines:\n",
    "    data = line.strip().split('\\t')\n",
    "    if len(data) != 17:\n",
    "        print('EntryID:', data[0])\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_URL = 'http://sabiork.h-its.org/sabioRestWebServices/kineticlawsExportTsv'\n",
    "#query = {'fields[]':['EntryID', 'Substrate', 'EnzymeType', 'Enzymename', 'PubMedID', 'Organism', 'UniprotID', 'ECNumber', 'Parameter', 'pH', 'Temperature']}\n",
    "query = {'fields[]':['EntryID', 'PubMedID', 'Organism', 'Substrate', 'EnzymeType', 'Enzymename', 'UniprotID', 'ECNumber', 'Parameter', 'pH', 'Temperature']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra code to rerun certain chunks/entries if needed \n",
    "start = time.time()\n",
    "query_string = \"EntryID:57731\"\n",
    "query['q'] = query_string\n",
    "request = requests.get(QUERY_URL, params = query)\n",
    "request.raise_for_status()\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "print(request.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra code to rerun certain chunks/entries if needed \n",
    "start = time.time()\n",
    "query_string = \"EntryID:58094\"\n",
    "query['q'] = query_string\n",
    "request = requests.get(QUERY_URL, params = query)\n",
    "request.raise_for_status()\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "print(request.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra code to rerun certain chunks/entries if needed \n",
    "start = time.time()\n",
    "query_string = \"EntryID:58472\"\n",
    "query['q'] = query_string\n",
    "request = requests.get(QUERY_URL, params = query)\n",
    "request.raise_for_status()\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "print(request.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra code to rerun certain chunks/entries if needed \n",
    "start = time.time()\n",
    "query_string = \"EntryID:60650\"\n",
    "query['q'] = query_string\n",
    "request = requests.get(QUERY_URL, params = query)\n",
    "request.raise_for_status()\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "print(request.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra code to rerun certain chunks/entries if needed \n",
    "start = time.time()\n",
    "query_string = \"EntryID:61738\"\n",
    "query['q'] = query_string\n",
    "request = requests.get(QUERY_URL, params = query)\n",
    "request.raise_for_status()\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "print(request.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra code to rerun certain chunks/entries if needed \n",
    "start = time.time()\n",
    "query_string = \"EntryID:65338\"\n",
    "query['q'] = query_string\n",
    "request = requests.get(QUERY_URL, params = query)\n",
    "request.raise_for_status()\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "print(request.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra code to rerun certain chunks/entries if needed \n",
    "start = time.time()\n",
    "query_string = \"EntryID:68232\"\n",
    "query['q'] = query_string\n",
    "request = requests.get(QUERY_URL, params = query)\n",
    "request.raise_for_status()\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "print(request.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra code to rerun certain chunks/entries if needed \n",
    "start = time.time()\n",
    "query_string = \"EntryID:71116\"\n",
    "query['q'] = query_string\n",
    "request = requests.get(QUERY_URL, params = query)\n",
    "request.raise_for_status()\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "print(request.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra code to rerun certain chunks/entries if needed \n",
    "start = time.time()\n",
    "query_string = \"EntryID:75485\"\n",
    "query['q'] = query_string\n",
    "request = requests.get(QUERY_URL, params = query)\n",
    "request.raise_for_status()\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "print(request.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resolve inconsistent formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdir = '../../../data/databases/Sabio-RK/'\n",
    "fname = 'dataset_download.tsv'\n",
    "with open(fdir+fname, 'r') as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unnecessary dashes and spaces so the corresponding entries are treated as missing values\n",
    "data = data.replace(\"\\t-\", \"\\t\")\n",
    "data = data.replace(\"\\t \", \"\\t\")\n",
    "data = data.replace(\"\\t-\\n\", \"\\t\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'Sabio-RK_dataset.tsv'\n",
    "with open(fdir+fname, 'w') as f:\n",
    "    f.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract and clean up $k_{cat}$ entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset as pandas dataframe and inspect the specifics of each parameter and their associated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdir = '../../../data/databases/Sabio-RK/'\n",
    "fname = 'Sabio-RK_dataset.tsv'\n",
    "df = pd.read_csv(fdir+fname, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(df['EntryID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['parameter.startValue'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract $k_{cat}$ values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df['parameter.type'] == 'kcat'\n",
    "df = df.loc[mask]\n",
    "n0 = len(df)\n",
    "n0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove missing $k_{cat}$ values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ~df['parameter.startValue'].isnull()\n",
    "print(\"Number of entries with no assigned value:\", n0 - np.sum(mask))\n",
    "df = df.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Remaining number of entries:\", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove unnecessary `parameter.name`, `parameter.type` and `parameter.associatedSpecies` columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['parameter.name', 'parameter.type', 'parameter.associatedSpecies'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore and reformat data entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `EntryID`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(df['EntryID']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 28k out of all 74k EntryIDs in the database have an associated $k_{cat}$ value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `PubMedID`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are parsed as floats but should be integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(df['PubMedID'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PubMedID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PubMedID'] = df['PubMedID'].astype('Int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Substrate`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end we reduce the dataset to $k_{cat}$ values only. If I understand correctly, in the DLKcat paper, the authors associate the $k_{cat}$ value with the substrate that has a measured $K_M$ value. If the $K_M$ values are measured for multiple substrates in the same reaction, then this would result in separate data inputs of the form $\\text{substrate}_1 \\rightarrow k_{cat}$ and $\\text{substrate}_2 \\rightarrow k_{cat}$ (in the neural net framework this can lead to different `kcat` predictions depending on the input substrate). We want to construct an input vector that includes all the substrates involved in the reaction (ignoring whether it has a measured $K_M$ value) in the form $[\\text{substrate}_1, \\text{substrate}_2, \\dotsc] \\rightarrow k_{cat}$. \n",
    "\n",
    "This is mentioned in the paper's discussion: \"Another challenge relates to reactions involving multiple substrates and those catalysed by heteromeric enzyme complexes. The multiple substrate SMILES and protein sequences that can be defined for such reactions can all function with DLKcat, thereby yielding multiple predicted kcat values for one reaction. We currently select the maximum kcat values in those cases, but it would be favourable to devise an approach that can predict one kcat value for each multi-substrate and/or heteromeric enzyme.\"\n",
    "\n",
    "Each entry is a list of substrates separated by `;` -- split into an array of individual substrate strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Substrate'] = df['Substrate'].apply(lambda x: np.sort(x.split(';')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `EnzymeType`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['EnzymeType']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutant_namelist = df['EnzymeType'][df['EnzymeType'].astype(str).apply(lambda x: 'mutant' in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from DLKcat\n",
    "import re\n",
    "\n",
    "for name in df['EnzymeType'].astype(str): \n",
    "    if 'wildtype' in name:\n",
    "        print (name +' -> wildtype')\n",
    "    else :\n",
    "    # if 'mutant' in EnzymeType or 'mutated' in EnzymeType:\n",
    "        mutant = re.findall('[A-Z]\\d+[A-Z]', name)  # re is of great use\n",
    "        print(name + ' -> '+ '/'.join(mutant))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The modifications given above that simplify the mutant/wild-type descriptors are performed in the DLKcat scripts. Omitting it now to keep things general."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Organism`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(df['Organism'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keeping the organism list as is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `UniprotID`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(df['UniprotID'][df['UniprotID'].apply(lambda x: type(x) != str)].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some entries do not have an associated UniprotID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[[3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some entries have multiple associated UniprotIDs (represent heteromeric protein complexes?). Detect such entries and list the UniprotIDs as an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['UniprotID'] = df['UniprotID'].apply(lambda x: np.empty(0) if pd.isnull(x) else np.sort(x.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['UniprotID'].astype(str).apply(lambda x : len(x)) == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `ECNumber`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple ECNumbers may be associated with an entry -- putting them in arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ECNumber'] = df['ECNumber'].apply(lambda x: np.empty(0) if pd.isnull(x) else np.sort(x.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df['ECNumber'].apply(lambda x: len(x) == 0)) & (df['UniprotID'].apply(lambda x: len(x) == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove entries that are missing both `ECNumber` and `UniprotID` (have no associated enzyme information) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[~mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `parameter`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some database entries have multiple associated $k_{cat}$ values. In DLKcat, the duplicates are removed by selecting the maximum $k_{cat}$ value as the ground truth. This is not necessarily the best approach as the multiple values may reflect experimental uncertainty or alternative specific experimental conditions. However, this is difficult to parse in an automated way, and dealing with such values more rigorously may require manual labour...\n",
    "\n",
    "Finally, note that in some cases the $k_{cat}$ values have not only an associated `parameter.startValue` but also an extra `parameter.endValue` (indicating an interval of possible values) or an associated `parameter.standardDeviation`. It's questionable whether these could be used as extra inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for entryID in np.unique(df['EntryID']):\n",
    "    n = np.sum(df['EntryID'] == entryID)\n",
    "    if n > 1:\n",
    "        i += 1\n",
    "        print('EntryID %d has %d kcat values' % (entryID, n))\n",
    "print('Number of entries with more than one kcat: %d' %i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['PubMedID'] == 15311923]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few are due to duplicated data entries. Remove those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df.astype(str).drop_duplicates().index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.astype(str).drop_duplicates().index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for entryID in np.unique(df['EntryID']):\n",
    "    n = np.sum(df['EntryID'] == entryID)\n",
    "    if n > 1:\n",
    "        i += 1\n",
    "        print('EntryID %d has %d kcat values' % (entryID, n))\n",
    "print('Number of entries with more than one kcat: %d' %i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `parameter.endValue`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the number of $k_{cat}$ values with an associated `endValue`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(~df['parameter.endValue'].isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relatively few entries exist, so ignoring `endValue` seems to be the way to go. Discard any entries that have both `startValue` and `endValue` defined, and remove the `parameter.endValue` column completely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df['parameter.endValue'].isnull()\n",
    "df = df.drop('parameter.endValue', axis=1)\n",
    "df = df.loc[mask]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `parameter.standardDeviation`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the number of $k_{cat}$ values with an associated `standardDeviation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(~df['parameter.standardDeviation'].isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard deviation is given for a relatively good chunk -- might be worth considering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `parameter.unit`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Units are not given in certain cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['parameter.unit'].apply(lambda x : pd.isnull(x))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having checked the paper for EntryID: 41969, the units are given as $s^{-1}$, so it's a human error in this case. Probably okay to assume that all `NaN` units can be converted to $s^{-1}$ (as done in DLKcat). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some $k_{cat}$ values have weird units associated with them. Some appear to be an error, also leading to wrong values due to an automatic unit conversion step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(df['parameter.unit'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['parameter.unit'] == 'J/mol']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typo having checked the paper (should be $s^{-1}$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['parameter.unit'] == 'M']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up the units. Keep only `s^(-1)` and convert `mol*s^(-1)*mol^(-1)` and `NaN` to `s^(-1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ((df['parameter.unit'].isnull()) | (df['parameter.unit'] == 'mol*s^(-1)*mol^(-1)'))\n",
    "df.loc[mask, 'parameter.unit'] = 's^(-1)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df['parameter.unit'] == 's^(-1)'\n",
    "df = df.loc[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `pH`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(~df['pH'].isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Temperature`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(~df['Temperature'].isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most entries seem to have an associated pH and temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'parameter.startValue': 'Value'})\n",
    "df = df.rename(columns={'parameter.standardDeviation': 'StandardDeviation'})\n",
    "df = df.rename(columns={'UniprotID': 'UniProtID'})\n",
    "df = df.rename(columns={'Enzymename': 'EnzymeName'})\n",
    "df = df.drop('parameter.unit', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['PubMedID', 'Organism', 'Substrate', 'ECNumber', 'EnzymeName', 'EnzymeType', 'UniProtID', 'pH', 'Temperature', 'Value', 'StandardDeviation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicated entries\n",
    "mask = df.astype(str).drop_duplicates().index\n",
    "df = df.loc[mask]\n",
    "df = df.reset_index(drop=True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove entries with kcat = 0\n",
    "# remove duplicated entries\n",
    "mask = df['Value'] != 0\n",
    "df = df.loc[mask]\n",
    "df = df.reset_index(drop=True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdir = '../../../data/databases/Sabio-RK/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(fdir+'kcats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(fdir+'kcats.json', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
